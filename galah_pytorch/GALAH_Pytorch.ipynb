{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsZWIabkvJUrjoi8bM7NQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potohodnica/magistrska/blob/main/GALAH_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAKG1vcCFwuF"
      },
      "outputs": [],
      "source": [
        "# System libraries\n",
        "import os, urllib\n",
        "import glob\n",
        "\n",
        "# Astro libraries\n",
        "import astropy.io.fits as pyfits\n",
        "\n",
        "# PyTorch Specific libraries\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Data manipulation and visualisation specific libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import reduce\n",
        "\n",
        "# For splitting the data into Train and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This piece of code is required to make use of the GPU instead of CPU for faster processing\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# If it prints \"cuda:0\" that means it has access to GPU. If it prints out \"cpu\", then it's still running on CPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust directory you want to work in\n",
        "working_directory = '/content/'\n",
        "os.chdir(working_directory)\n",
        "\n",
        "# Choose if you want to plot the normalised or reduced spectra\n",
        "normalised = False\n",
        "\n",
        "# Choose if you want to save the plot as PNG file\n",
        "savefig = True\n",
        "\n",
        "# Print messages\n",
        "printmsg = False"
      ],
      "metadata": {
        "id": "2diJMy-OMibQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_spectra(sobject_id,ccd):\n",
        "    \"\"\"\n",
        "    Try to download the specfici spectrum from Datacentral\n",
        "    \"\"\"\n",
        "\n",
        "    ccd_dict = {\n",
        "      1: \"B\",\n",
        "      2: \"G\",\n",
        "      3: \"R\",\n",
        "      4: \"I\"\n",
        "      }\n",
        "   \n",
        "    try:\n",
        "      link = 'https://datacentral.org.au/vo/slink/links?ID=' + str(sobject_id) + '&DR=galah_dr3&IDX=0&FILT=' + ccd_dict[ccd] + '&RESPONSEFORMAT=fits'\n",
        "      urllib.request.urlretrieve(link, '/content/'+str(sobject_id)+str(ccd)+'.fits')\n",
        "      return [working_directory+str(sobject_id)+str(ccd)+'.fits']\n",
        "    except:\n",
        "      if printmsg:\n",
        "        print('FITS '+str(sobject_id)+str(ccd)+' not available')\n",
        "      return []"
      ],
      "metadata": {
        "id": "UQVCO8kfMlL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_spectra(sobject_id, tutorial=True):\n",
        "    \"\"\"\n",
        "    Read in all available CCDs and give back a dictionary\n",
        "    Download them if not already in working directory\n",
        "    \"\"\"\n",
        "    \n",
        "    # Check if FITS files already available in working directory\n",
        "    fits_files = [[], [], [], []]\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        fits_files[each_ccd-1] = glob.glob(working_directory+str(sobject_id)+str(each_ccd)+'.fits')\n",
        "    # If not already available, try to download\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1] == []:\n",
        "            fits_files[each_ccd-1] = download_spectra(sobject_id,each_ccd)\n",
        "    \n",
        "    spectrum = dict()\n",
        "\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1]!=[]:\n",
        "            fits = pyfits.open(fits_files[each_ccd-1][0])\n",
        "\n",
        "            # Extension 0: Reduced spectrum\n",
        "            # Extension 1: Relative error spectrum\n",
        "            # Extension 4: Normalised spectrum, NB: cut for CCD4\n",
        "\n",
        "            if len(fits) == 5:\n",
        "              ext1 = True\n",
        "              ext4 = True\n",
        "            elif len(fits) == 2:\n",
        "              ext1 = True\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "            else:\n",
        "              ext1 = False\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Relative error spectrum and normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "\n",
        "            # Extract wavelength grid for the reduced spectrum\n",
        "            start_wavelength = fits[0].header[\"CRVAL1\"]\n",
        "            dispersion       = fits[0].header[\"CDELT1\"]\n",
        "            nr_pixels        = fits[0].header[\"NAXIS1\"]\n",
        "            reference_pixel  = fits[0].header[\"CRPIX1\"]\n",
        "            if reference_pixel == 0:\n",
        "                reference_pixel = 1\n",
        "            spectrum['wave_red_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            if ext4:\n",
        "              # Extract wavelength grid for the normalised spectrum\n",
        "\n",
        "              start_wavelength = fits[4].header[\"CRVAL1\"]\n",
        "              dispersion       = fits[4].header[\"CDELT1\"]\n",
        "              nr_pixels        = fits[4].header[\"NAXIS1\"]\n",
        "              reference_pixel  = fits[4].header[\"CRPIX1\"]\n",
        "              if reference_pixel == 0:\n",
        "                reference_pixel=1\n",
        "              spectrum['wave_norm_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            # Extract flux and flux error of reduced spectrum\n",
        "            # Added byteswap for Pandas use ----> https://stackoverflow.com/questions/30283836/creating-pandas-dataframe-from-numpy-array-leads-to-strange-errors\n",
        "            spectrum['sob_red_'+str(each_ccd)]  = np.array(fits[0].data).byteswap().newbyteorder()\n",
        "            if ext1:\n",
        "              spectrum['uob_red_'+str(each_ccd)]  = np.array(fits[0].data * fits[1].data)\n",
        "\n",
        "            if ext4 and ext1: \n",
        "              # Extract flux and flux error of normalised spectrum\n",
        "              spectrum['sob_norm_'+str(each_ccd)] = np.array(fits[4].data)\n",
        "              if each_ccd != 4:\n",
        "                 spectrum['uob_norm_'+str(each_ccd)] = np.array(fits[4].data * fits[1].data)\n",
        "              else:\n",
        "                 # for normalised error of CCD4, only used appropriate parts of error spectrum\n",
        "                 spectrum['uob_norm_4'] = np.array(fits[4].data * (fits[1].data)[-len(spectrum['sob_norm_4']):])\n",
        "\n",
        "            fits.close()\n",
        "        else:\n",
        "            spectrum['wave_red_'+str(each_ccd)] = []\n",
        "            spectrum['wave_norm_'+str(each_ccd)] = []\n",
        "            spectrum['sob_red_'+str(each_ccd)] = []\n",
        "            spectrum['sob_norm_'+str(each_ccd)] = []\n",
        "            spectrum['uob_red_'+str(each_ccd)] = []\n",
        "            spectrum['uob_norm_'+str(each_ccd)] = []\n",
        "    \n",
        "    spectrum['wave_red'] = np.concatenate(([spectrum['wave_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    spectrum['sob_red'] = np.concatenate(([spectrum['sob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext4:\n",
        "       spectrum['sob_norm'] = np.concatenate(([spectrum['sob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "       spectrum['wave_norm'] = np.concatenate(([spectrum['wave_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1:\n",
        "       spectrum['uob_red'] = np.concatenate(([spectrum['uob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1 and ext4:\n",
        "       spectrum['uob_norm'] = np.concatenate(([spectrum['uob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    \n",
        "   \n",
        "    return spectrum"
      ],
      "metadata": {
        "id": "Ulmue2_zMxId"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}