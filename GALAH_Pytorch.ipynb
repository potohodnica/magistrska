{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMnT6yUGgHHqFfsMX+Tgqq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potohodnica/magistrska/blob/main/GALAH_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lAKG1vcCFwuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2f3eb982-3d4a-4191-b50c-d4b854bc36ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@title Load libraries\n",
        "\n",
        "# System libraries\n",
        "import os, urllib\n",
        "import glob\n",
        "\n",
        "# Astro libraries\n",
        "import astropy.io.fits as pyfits\n",
        "\n",
        "# PyTorch Specific libraries\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Data manipulation and visualisation specific libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import reduce\n",
        "\n",
        "# For splitting the data into Train and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This piece of code is required to make use of the GPU instead of CPU for faster processing\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# If it prints \"cuda:0\" that means it has access to GPU. If it prints out \"cpu\", then it's still running on CPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings\n",
        "\n",
        "# Adjust directory you want to work in\n",
        "working_directory = '/content/'\n",
        "os.chdir(working_directory)\n",
        "\n",
        "# Choose if you want to plot the normalised or reduced spectra\n",
        "normalised = False\n",
        "\n",
        "# Choose if you want to save the plot as PNG file\n",
        "savefig = True\n",
        "\n",
        "# Print messages\n",
        "printmsg = False\n",
        "\n",
        "# Number of binaries and all types of spectra to work with. Input n = -1, if you want all available spectra.\n",
        "n_bin = 100\n",
        "n_all = 1000"
      ],
      "metadata": {
        "id": "2diJMy-OMibQ",
        "cellView": "form"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download sobject_ids\n",
        "\n",
        "def download_sobject_ids(bin_or_all):\n",
        "  try:\n",
        "    link= 'https://raw.githubusercontent.com/potohodnica/magistrska/main/galah_binaries.tsv'\n",
        "    urllib.request.urlretrieve(link, working_directory + 'galah_' + bin_or_all + '.tsv')\n",
        "  except:\n",
        "    if printmsg:\n",
        "      print('Download error osubject_ids.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HK2gnb-O9wjy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Edit and sort sobject_ids\n",
        "\n",
        "def sort_sobject_ids(bin_or_all, n):\n",
        "  df = pd.read_csv(working_directory + \"galah_\" + bin_or_all + \".tsv\", on_bad_lines='skip', sep = \";\", skiprows=40, usecols = ['GALAH']).drop([0, 1])\n",
        "  df.rename(columns={'GALAH':'galah_' + bin_or_all}, inplace=True)\n",
        "  if not n == -1:\n",
        "    df = df.sample(n=n, random_state=42)\n",
        "  return df"
      ],
      "metadata": {
        "cellView": "form",
        "id": "H7UZIgzUggZg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download spectra\n",
        "\n",
        "def download_spectra(sobject_id,ccd):\n",
        "    \"\"\"\n",
        "    Try to download the specfici spectrum from Datacentral\n",
        "    \"\"\"\n",
        "\n",
        "    ccd_dict = {\n",
        "      1: \"B\",\n",
        "      2: \"G\",\n",
        "      3: \"R\",\n",
        "      4: \"I\"\n",
        "      }\n",
        "   \n",
        "    try:\n",
        "      link = 'https://datacentral.org.au/vo/slink/links?ID=' + str(sobject_id) + '&DR=galah_dr3&IDX=0&FILT=' + ccd_dict[ccd] + '&RESPONSEFORMAT=fits'\n",
        "      urllib.request.urlretrieve(link, working_directory + str(sobject_id) + str(ccd) + '.fits')\n",
        "      return [working_directory + str(sobject_id) + str(ccd) + '.fits']\n",
        "    except:\n",
        "      if printmsg:\n",
        "        print('FITS ' + str(sobject_id) + str(ccd) + ' not available')\n",
        "      return []"
      ],
      "metadata": {
        "id": "UQVCO8kfMlL3",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read spectra\n",
        "\n",
        "def read_spectra(sobject_id, tutorial=True):\n",
        "    \"\"\"\n",
        "    Read in all available CCDs and give back a dictionary\n",
        "    Download them if not already in working directory\n",
        "    \"\"\"\n",
        "    \n",
        "    # Check if FITS files already available in working directory\n",
        "    fits_files = [[], [], [], []]\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        fits_files[each_ccd-1] = glob.glob(working_directory+str(sobject_id)+str(each_ccd)+'.fits')\n",
        "    # If not already available, try to download\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1] == []:\n",
        "            fits_files[each_ccd-1] = download_spectra(sobject_id,each_ccd)\n",
        "    \n",
        "    spectrum = dict()\n",
        "\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1]!=[]:\n",
        "            fits = pyfits.open(fits_files[each_ccd-1][0])\n",
        "\n",
        "            # Extension 0: Reduced spectrum\n",
        "            # Extension 1: Relative error spectrum\n",
        "            # Extension 4: Normalised spectrum, NB: cut for CCD4\n",
        "\n",
        "            if len(fits) == 5:\n",
        "              ext1 = True\n",
        "              ext4 = True\n",
        "            elif len(fits) == 2:\n",
        "              ext1 = True\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "            else:\n",
        "              ext1 = False\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Relative error spectrum and normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "\n",
        "            # Extract wavelength grid for the reduced spectrum\n",
        "            start_wavelength = fits[0].header[\"CRVAL1\"]\n",
        "            dispersion       = fits[0].header[\"CDELT1\"]\n",
        "            nr_pixels        = fits[0].header[\"NAXIS1\"]\n",
        "            reference_pixel  = fits[0].header[\"CRPIX1\"]\n",
        "            if reference_pixel == 0:\n",
        "                reference_pixel = 1\n",
        "            spectrum['wave_red_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            if ext4:\n",
        "              # Extract wavelength grid for the normalised spectrum\n",
        "\n",
        "              start_wavelength = fits[4].header[\"CRVAL1\"]\n",
        "              dispersion       = fits[4].header[\"CDELT1\"]\n",
        "              nr_pixels        = fits[4].header[\"NAXIS1\"]\n",
        "              reference_pixel  = fits[4].header[\"CRPIX1\"]\n",
        "              if reference_pixel == 0:\n",
        "                reference_pixel=1\n",
        "              spectrum['wave_norm_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            # Extract flux and flux error of reduced spectrum\n",
        "            # Added byteswap for Pandas use ----> https://stackoverflow.com/questions/30283836/creating-pandas-dataframe-from-numpy-array-leads-to-strange-errors\n",
        "            spectrum['sob_red_'+str(each_ccd)]  = np.array(fits[0].data).byteswap().newbyteorder()\n",
        "            if ext1:\n",
        "              spectrum['uob_red_'+str(each_ccd)]  = np.array(fits[0].data * fits[1].data)\n",
        "\n",
        "            if ext4 and ext1: \n",
        "              # Extract flux and flux error of normalised spectrum\n",
        "              spectrum['sob_norm_'+str(each_ccd)] = np.array(fits[4].data)\n",
        "              if each_ccd != 4:\n",
        "                 spectrum['uob_norm_'+str(each_ccd)] = np.array(fits[4].data * fits[1].data)\n",
        "              else:\n",
        "                 # for normalised error of CCD4, only used appropriate parts of error spectrum\n",
        "                 spectrum['uob_norm_4'] = np.array(fits[4].data * (fits[1].data)[-len(spectrum['sob_norm_4']):])\n",
        "\n",
        "            fits.close()\n",
        "        else:\n",
        "            spectrum['wave_red_'+str(each_ccd)] = []\n",
        "            spectrum['wave_norm_'+str(each_ccd)] = []\n",
        "            spectrum['sob_red_'+str(each_ccd)] = []\n",
        "            spectrum['sob_norm_'+str(each_ccd)] = []\n",
        "            spectrum['uob_red_'+str(each_ccd)] = []\n",
        "            spectrum['uob_norm_'+str(each_ccd)] = []\n",
        "    \n",
        "    spectrum['wave_red'] = np.concatenate(([spectrum['wave_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    spectrum['sob_red'] = np.concatenate(([spectrum['sob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext4:\n",
        "       spectrum['sob_norm'] = np.concatenate(([spectrum['sob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "       spectrum['wave_norm'] = np.concatenate(([spectrum['wave_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1:\n",
        "       spectrum['uob_red'] = np.concatenate(([spectrum['uob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1 and ext4:\n",
        "       spectrum['uob_norm'] = np.concatenate(([spectrum['uob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    \n",
        "   \n",
        "    return spectrum"
      ],
      "metadata": {
        "id": "Ulmue2_zMxId",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(working_directory + 'galah_binaries.tsv'):\n",
        "  download_sobject_ids('bin')\n",
        "if not os.path.isfile(working_directory + 'galah_all.tsv'):\n",
        "  download_sobject_ids('all')\n",
        "\n",
        "df_bin = sort_sobject_ids('bin', n_bin)\n",
        "df_all = sort_sobject_ids('all', n_all)\n",
        "print(df_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WABIlNpqBJ-U",
        "outputId": "cd0c04e0-e425-4cc0-ec7d-fd0634f6c730"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            galah_all\n",
            "5367  170418002701232\n",
            "4327  161212002101320\n",
            "201   170723004101143\n",
            "3261  160421005101009\n",
            "3495  160520002101355\n",
            "...               ...\n",
            "1672  150107002701374\n",
            "4917  170216002801194\n",
            "4810  170202001701016\n",
            "2339  150827002901112\n",
            "4506  170107002601087\n",
            "\n",
            "[1000 rows x 1 columns]\n"
          ]
        }
      ]
    }
  ]
}