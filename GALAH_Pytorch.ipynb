{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6/OMLGCVkYshOtpQSDIDo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/potohodnica/magistrska/blob/main/GALAH_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lAKG1vcCFwuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "3e4cf04f-47a1-41e8-9b55-517462efaffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "#@title Load libraries\n",
        "\n",
        "# System libraries\n",
        "import os, urllib\n",
        "import glob\n",
        "\n",
        "# Astro libraries\n",
        "import astropy.io.fits as pyfits\n",
        "\n",
        "# PyTorch Specific libraries\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# Data manipulation and visualisation specific libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from functools import reduce\n",
        "\n",
        "# For splitting the data into Train and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# This piece of code is required to make use of the GPU instead of CPU for faster processing\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# If it prints \"cuda:0\" that means it has access to GPU. If it prints out \"cpu\", then it's still running on CPU."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Settings\n",
        "\n",
        "# Adjust directory you want to work in\n",
        "working_directory = '/content/'\n",
        "os.chdir(working_directory)\n",
        "\n",
        "# Choose if you want to plot the normalised or reduced spectra\n",
        "normalised = False\n",
        "\n",
        "# Choose if you want to save the plot as PNG file\n",
        "savefig = True\n",
        "\n",
        "# Print messages\n",
        "printmsg = False\n",
        "\n",
        "# Number of binaries and all types of spectra to work with. Input n = -1, if you want all available spectra.\n",
        "n_bin = 0\n",
        "n_all = 1"
      ],
      "metadata": {
        "id": "2diJMy-OMibQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download sobject_ids\n",
        "\n",
        "def download_sobject_ids(bin_or_all):\n",
        "  try:\n",
        "    link= 'https://raw.githubusercontent.com/potohodnica/magistrska/main/galah_binaries.tsv'\n",
        "    urllib.request.urlretrieve(link, working_directory + 'galah_' + bin_or_all + '.tsv')\n",
        "  except:\n",
        "    if printmsg:\n",
        "      print('Download error osubject_ids.')"
      ],
      "metadata": {
        "id": "HK2gnb-O9wjy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Sort and merge sobject_ids\n",
        "\n",
        "def sort_sobject_ids(bin_or_all, n):\n",
        "  df = pd.read_csv(working_directory + \"galah_\" + bin_or_all + \".tsv\", on_bad_lines='skip', sep = \";\", skiprows=40, usecols = ['GALAH']).drop([0, 1])\n",
        "  df.rename(columns={'GALAH': 'sobject_id'}, inplace=True)\n",
        "  if not n == -1:\n",
        "    df = df.sample(n=n, random_state=42)\n",
        "  return df\n",
        "\n",
        "def merge_sobject_ids():\n",
        "  if not os.path.isfile(working_directory + 'galah_binaries.tsv'):\n",
        "      download_sobject_ids('bin')\n",
        "  if not os.path.isfile(working_directory + 'galah_all.tsv'):\n",
        "      download_sobject_ids('all')\n",
        "\n",
        "  df_bin = sort_sobject_ids('bin', n_bin)\n",
        "  df_all = sort_sobject_ids('all', n_all)\n",
        "  df_merged = pd.merge(df_all, df_bin, how='outer', indicator=True)\n",
        "\n",
        "  df_merged.loc[df_merged['_merge']  == 'left_only', 'bin_tf'] = 0\n",
        "  df_merged.loc[df_merged['_merge']  == 'both', 'bin_tf'] = 1\n",
        "  df_merged.drop(['_merge'], axis=1, inplace=True)\n",
        "  return df_merged"
      ],
      "metadata": {
        "id": "H7UZIgzUggZg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download spectra\n",
        "\n",
        "def download_spectra(sobject_id,ccd):\n",
        "    \"\"\"\n",
        "    Try to download the specfici spectrum from Datacentral\n",
        "    \"\"\"\n",
        "\n",
        "    ccd_dict = {\n",
        "      1: \"B\",\n",
        "      2: \"G\",\n",
        "      3: \"R\",\n",
        "      4: \"I\"\n",
        "      }\n",
        "   \n",
        "    try:\n",
        "      link = 'https://datacentral.org.au/vo/slink/links?ID=' + str(sobject_id) + '&DR=galah_dr3&IDX=0&FILT=' + ccd_dict[ccd] + '&RESPONSEFORMAT=fits'\n",
        "      urllib.request.urlretrieve(link, working_directory + str(sobject_id) + str(ccd) + '.fits')\n",
        "      return [working_directory + str(sobject_id) + str(ccd) + '.fits']\n",
        "    except:\n",
        "      if printmsg:\n",
        "        print('FITS ' + str(sobject_id) + str(ccd) + ' not available')\n",
        "      return []"
      ],
      "metadata": {
        "id": "UQVCO8kfMlL3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read spectra\n",
        "\n",
        "def read_spectra(sobject_id):\n",
        "    \"\"\"\n",
        "    Read in all available CCDs and give back a dictionary\n",
        "    Download them if not already in working directory\n",
        "    \"\"\"\n",
        "    \n",
        "    # Check if FITS files already available in working directory\n",
        "    fits_files = [[], [], [], []]\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        fits_files[each_ccd-1] = glob.glob(working_directory+str(sobject_id)+str(each_ccd)+'.fits')\n",
        "    # If not already available, try to download\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1] == []:\n",
        "            fits_files[each_ccd-1] = download_spectra(sobject_id,each_ccd)\n",
        "    \n",
        "    spectrum = dict()\n",
        "\n",
        "    for each_ccd in [1,2,3,4]:\n",
        "        if fits_files[each_ccd-1]!=[]:\n",
        "            fits = pyfits.open(fits_files[each_ccd-1][0])\n",
        "\n",
        "            # Extension 0: Reduced spectrum\n",
        "            # Extension 1: Relative error spectrum\n",
        "            # Extension 4: Normalised spectrum, NB: cut for CCD4\n",
        "\n",
        "            if len(fits) == 5:\n",
        "              ext1 = True\n",
        "              ext4 = True\n",
        "            elif len(fits) == 2:\n",
        "              ext1 = True\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "            else:\n",
        "              ext1 = False\n",
        "              ext4 = False\n",
        "              if printmsg:\n",
        "                print('Relative error spectrum and normalised spectrum missing in',str(each_ccd),'ccd.')\n",
        "\n",
        "            # Extract wavelength grid for the reduced spectrum\n",
        "            start_wavelength = fits[0].header[\"CRVAL1\"]\n",
        "            dispersion       = fits[0].header[\"CDELT1\"]\n",
        "            nr_pixels        = fits[0].header[\"NAXIS1\"]\n",
        "            reference_pixel  = fits[0].header[\"CRPIX1\"]\n",
        "            if reference_pixel == 0:\n",
        "                reference_pixel = 1\n",
        "            spectrum['wave_red_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            if ext4:\n",
        "              # Extract wavelength grid for the normalised spectrum\n",
        "\n",
        "              start_wavelength = fits[4].header[\"CRVAL1\"]\n",
        "              dispersion       = fits[4].header[\"CDELT1\"]\n",
        "              nr_pixels        = fits[4].header[\"NAXIS1\"]\n",
        "              reference_pixel  = fits[4].header[\"CRPIX1\"]\n",
        "              if reference_pixel == 0:\n",
        "                reference_pixel=1\n",
        "              spectrum['wave_norm_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength)\n",
        "\n",
        "            # Extract flux and flux error of reduced spectrum\n",
        "            # Added byteswap for Pandas use ----> https://stackoverflow.com/questions/30283836/creating-pandas-dataframe-from-numpy-array-leads-to-strange-errors\n",
        "            spectrum['sob_red_'+str(each_ccd)]  = np.array(fits[0].data).byteswap().newbyteorder()\n",
        "            if ext1:\n",
        "              spectrum['uob_red_'+str(each_ccd)]  = np.array(fits[0].data * fits[1].data)\n",
        "\n",
        "            if ext4 and ext1: \n",
        "              # Extract flux and flux error of normalised spectrum\n",
        "              spectrum['sob_norm_'+str(each_ccd)] = np.array(fits[4].data)\n",
        "              if each_ccd != 4:\n",
        "                 spectrum['uob_norm_'+str(each_ccd)] = np.array(fits[4].data * fits[1].data)\n",
        "              else:\n",
        "                 # for normalised error of CCD4, only used appropriate parts of error spectrum\n",
        "                 spectrum['uob_norm_4'] = np.array(fits[4].data * (fits[1].data)[-len(spectrum['sob_norm_4']):])\n",
        "\n",
        "            fits.close()\n",
        "        else:\n",
        "            spectrum['wave_red_'+str(each_ccd)] = []\n",
        "            spectrum['wave_norm_'+str(each_ccd)] = []\n",
        "            spectrum['sob_red_'+str(each_ccd)] = []\n",
        "            spectrum['sob_norm_'+str(each_ccd)] = []\n",
        "            spectrum['uob_red_'+str(each_ccd)] = []\n",
        "            spectrum['uob_norm_'+str(each_ccd)] = []\n",
        "    \n",
        "    spectrum['wave_red'] = np.concatenate(([spectrum['wave_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    spectrum['sob_red'] = np.concatenate(([spectrum['sob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext4:\n",
        "       spectrum['sob_norm'] = np.concatenate(([spectrum['sob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "       spectrum['wave_norm'] = np.concatenate(([spectrum['wave_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1:\n",
        "       spectrum['uob_red'] = np.concatenate(([spectrum['uob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    if ext1 and ext4:\n",
        "       spectrum['uob_norm'] = np.concatenate(([spectrum['uob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
        "    \n",
        "   \n",
        "    return spectrum"
      ],
      "metadata": {
        "id": "Ulmue2_zMxId"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrum1_dfs = []\n",
        "spectrum2_dfs = []\n",
        "spectrum3_dfs = []\n",
        "spectrum4_dfs = []\n",
        "\n",
        "df_sobject_ids = merge_sobject_ids()\n",
        "print(df_sobject_ids)\n",
        "for sobject_id in df_sobject_ids[\"sobject_id\"].tolist():\n",
        "    spectrum = read_spectra(sobject_id)\n",
        "    B = np.array(spectrum['sob_red_1'])\n",
        "    G = np.array(spectrum['sob_red_2'])\n",
        "    R = np.array(spectrum['sob_red_3'])\n",
        "    I = np.array(spectrum['sob_red_4'])\n",
        "\n",
        "    B = np.pad(B.astype(float), (0, 4096*1 - B.size), mode='constant', constant_values=np.nan).reshape(4096,)\n",
        "    G = np.pad(G.astype(float), (0, 4096*1 - G.size), mode='constant', constant_values=np.nan).reshape(4096,)\n",
        "    R = np.pad(R.astype(float), (0, 4096*1 - R.size), mode='constant', constant_values=np.nan).reshape(4096,)\n",
        "    I = np.pad(I.astype(float), (0, 4096*1 - I.size), mode='constant', constant_values=np.nan).reshape(4096,)\n",
        "\n",
        "    stacked = np.stack([B, G, R, I], axis=1)\n",
        "    \n",
        "    print(stacked[1])\n",
        "    #spectrum1_dfs.append(pd.DataFrame({str(sobject_id) + '1': spectrum['sob_red_1']}))\n",
        "    #spectrum2_dfs.append(pd.DataFrame({str(sobject_id) + '2': spectrum['sob_red_2']}))\n",
        "    #spectrum3_dfs.append(pd.DataFrame({str(sobject_id) + '3': spectrum['sob_red_3']}))\n",
        "    #spectrum4_dfs.append(pd.DataFrame({str(sobject_id) + '4': spectrum['sob_red_4']}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WABIlNpqBJ-U",
        "outputId": "00552821-6ec2-4ecf-9a0c-58dea784af86"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        sobject_id  bin_tf\n",
            "0  170418002701232     0.0\n",
            "[0.91004311        nan 0.97940986 0.95867275]\n"
          ]
        }
      ]
    }
  ]
}